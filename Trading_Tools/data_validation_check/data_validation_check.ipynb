{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZDmMhjaJyze",
        "outputId": "d28b2f1f-1181-473b-df32-9ac4598f05bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Files saved:\n",
            " - CFDs: data_cleaned_cfds_glencore.csv\n",
            " - DFLs: data_cleaned_dfls_glencore.csv\n",
            " - Spreads: data_cleaned_spreads_glencore.csv\n",
            " - EFPs: data_cleaned_efps_glencore.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/Glencore recap 11062025.xlsx\"\n",
        "xls = pd.ExcelFile(file_path)\n",
        "sheet_data = xls.parse(\"Sheet1\", header=None)\n",
        "\n",
        "weekly_cfds_rows = []\n",
        "collecting = False\n",
        "\n",
        "for index, row in sheet_data.iterrows():\n",
        "    first_cell = str(row[0]).strip()\n",
        "\n",
        "    if first_cell.startswith(\"Week1\"):\n",
        "        collecting = True\n",
        "\n",
        "    if collecting:\n",
        "        if str(first_cell).startswith(\"Week\"):\n",
        "            weekly_cfds_rows.append([row[0], row[1], row[3], row[4]])\n",
        "        else:\n",
        "            break\n",
        "\n",
        "weekly_cfds_df = pd.DataFrame(weekly_cfds_rows, columns=['Week', 'Date Range', 'Month', 'Value'])\n",
        "weekly_cfds_df = weekly_cfds_df.reset_index(drop=True)\n",
        "\n",
        "dfls_rows = []\n",
        "\n",
        "for index, row in sheet_data.iterrows():\n",
        "    month = row[7]\n",
        "    value = row[8]\n",
        "\n",
        "    if pd.notna(month) and pd.notna(value):\n",
        "        dfls_rows.append([month, value])\n",
        "\n",
        "dfls_df = pd.DataFrame(dfls_rows, columns=['Month', 'Value'])\n",
        "\n",
        "spreads_rows = []\n",
        "\n",
        "for index, row in sheet_data.iterrows():\n",
        "    col3 = row[3]\n",
        "    col4 = row[4]\n",
        "\n",
        "    if pd.notna(col3) and pd.notna(col4):\n",
        "        if \"ICE\" in str(col3) or \"/\" in str(col3):\n",
        "            spreads_rows.append([col3, col4])\n",
        "\n",
        "spreads_df = pd.DataFrame(spreads_rows, columns=['Spread', 'Value'])\n",
        "\n",
        "efps_from_dfls_df = dfls_df.tail(3).reset_index(drop=True)\n",
        "dfls_df = dfls_df.iloc[:-3].reset_index(drop=True)\n",
        "\n",
        "cfds_output_path = \"data_cleaned_cfds_glencore.csv\"\n",
        "dfls_output_path = \"data_cleaned_dfls_glencore.csv\"\n",
        "spreads_output_path = \"data_cleaned_spreads_glencore.csv\"\n",
        "efp_output_path = \"data_cleaned_efps_glencore.csv\"\n",
        "\n",
        "weekly_cfds_df.to_csv(cfds_output_path, index=False)\n",
        "dfls_df.to_csv(dfls_output_path, index=False)\n",
        "spreads_df.to_csv(spreads_output_path, index=False)\n",
        "\n",
        "efps_from_dfls_df.to_csv(\"data_cleaned_efps_glencore.csv\", index=False)\n",
        "print(\"✅ Files saved:\")\n",
        "print(f\" - CFDs: {cfds_output_path}\")\n",
        "print(f\" - DFLs: {dfls_output_path}\")\n",
        "print(f\" - Spreads: {spreads_output_path}\")\n",
        "print(f\" - EFPs: {efp_output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"marketclose 11062025.xls\"\n",
        "xls = pd.ExcelFile(file_path)\n",
        "sheet_data = xls.parse(xls.sheet_names[0], header=None)\n",
        "\n",
        "weekly_cfds_rows = []\n",
        "cfds_section_found = False\n",
        "\n",
        "for index, row in sheet_data.iterrows():\n",
        "    row_str = str(row[0])\n",
        "\n",
        "    if \"CFD's\" in row_str:\n",
        "        cfds_section_found = True\n",
        "        continue\n",
        "\n",
        "    if cfds_section_found:\n",
        "        if pd.notna(row[0]) and pd.notna(row[1]) and pd.notna(row[2]):\n",
        "            weekly_cfds_rows.append([row[0], row[1], row[2]])\n",
        "        elif pd.isna(row[0]) or \"All Month\" in str(row[0]):\n",
        "            break\n",
        "\n",
        "weekly_cfds_df = pd.DataFrame(weekly_cfds_rows, columns=['Week Range', 'Month', 'Value'])\n",
        "\n",
        "dfls_rows = []\n",
        "dfl_section_found = False\n",
        "\n",
        "for index, row in sheet_data.iterrows():\n",
        "    col_f = str(row[5]).strip() if pd.notna(row[5]) else \"\"\n",
        "    col_g = row[6]\n",
        "\n",
        "    if not dfl_section_found:\n",
        "        if col_f == \"Dated Front Line ICE\":\n",
        "            dfl_section_found = True\n",
        "        continue\n",
        "\n",
        "    if dfl_section_found:\n",
        "        if \"Calendar WTI/Brent Swap\" in col_f:\n",
        "            break\n",
        "\n",
        "        if col_f and pd.notna(col_g):\n",
        "            dfls_rows.append([col_f, col_g])\n",
        "\n",
        "dfls_df = pd.DataFrame(dfls_rows, columns=['Month', 'Value'])\n",
        "\n",
        "cfds_output_path = \"data_cleaned_cfds_source.csv\"\n",
        "dfls_output_path = \"data_cleaned_dfls_source.csv\"\n",
        "\n",
        "weekly_cfds_df.to_csv(cfds_output_path, index=False)\n",
        "dfls_df.to_csv(dfls_output_path, index=False)\n",
        "\n",
        "print(\"✅ Files saved:\")\n",
        "print(f\" - CFDs: {cfds_output_path}\")\n",
        "print(f\" - DFLs: {dfls_output_path}\")\n",
        "\n",
        "spreads_rows = []\n",
        "spreads_started = False\n",
        "\n",
        "for index, row in sheet_data.iterrows():\n",
        "    col_k = str(row[10]).strip() if pd.notna(row[10]) else \"\"\n",
        "    col_l = str(row[11]).strip() if pd.notna(row[11]) else \"\"\n",
        "    col_m = row[12]\n",
        "\n",
        "    if not spreads_started and \"Brent Spreads\" in col_l:\n",
        "        spreads_started = True\n",
        "        continue\n",
        "\n",
        "    if spreads_started:\n",
        "        if not col_k and not col_l and pd.isna(col_m):\n",
        "            break\n",
        "        if col_k and col_l and pd.notna(col_m):\n",
        "            spreads_rows.append([col_k.strip(), col_l.strip(), col_m])\n",
        "\n",
        "spreads_df = pd.DataFrame(spreads_rows, columns=[\"Month1\", \"Month2\", \"Value\"])\n",
        "spreads_df.to_csv(\"data_cleaned_spreads_source.csv\", index=False)\n",
        "print(\" - Spreads: data_cleaned_spreads_source.csv\")\n",
        "\n",
        "brent_efps_rows = []\n",
        "efp_section_started = False\n",
        "\n",
        "for index, row in sheet_data.iterrows():\n",
        "    col_a = str(row[0]).strip() if pd.notna(row[0]) else \"\"\n",
        "    col_b = row[1]\n",
        "\n",
        "    if not efp_section_started and \"Brent EFP\" in col_a:\n",
        "        efp_section_started = True\n",
        "        continue\n",
        "\n",
        "    if efp_section_started:\n",
        "        if not col_a and pd.isna(col_b):\n",
        "            break\n",
        "        if col_a and pd.notna(col_b):\n",
        "            brent_efps_rows.append([col_a, col_b])\n",
        "\n",
        "brent_efps_df = pd.DataFrame(brent_efps_rows, columns=[\"Month\", \"Value\"])\n",
        "brent_efps_df.to_csv(\"data_cleaned_brent_efps_source.csv\", index=False)\n",
        "print(\" - Brent EFPs: data_cleaned_brent_efps_source.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HaKfLqMTKEG",
        "outputId": "c3b3aaef-009e-4760-d7cb-67de70def41d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Files saved:\n",
            " - CFDs: data_cleaned_cfds_source.csv\n",
            " - DFLs: data_cleaned_dfls_source.csv\n",
            " - Spreads: data_cleaned_spreads_source.csv\n",
            " - Brent EFPs: data_cleaned_brent_efps_source.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv(\"/content/data_cleaned_cfds_glencore.csv\")\n",
        "df2 = pd.read_csv(\"/content/data_cleaned_cfds_source.csv\")\n",
        "\n",
        "df1.rename(columns={\"Date Range\": \"Week Range\"}, inplace=True)\n",
        "\n",
        "df1[\"Week Range\"] = df1[\"Week Range\"].astype(str).str.strip()\n",
        "df1[\"Month\"] = df1[\"Month\"].astype(str).str.strip()\n",
        "\n",
        "df2[\"Week Range\"] = df2[\"Week Range\"].astype(str).str.strip()\n",
        "df2[\"Month\"] = df2[\"Month\"].astype(str).str.strip()\n",
        "\n",
        "merged = pd.merge(df1, df2, on=[\"Week Range\", \"Month\"], how=\"outer\", suffixes=('_file1', '_file2'))\n",
        "\n",
        "for idx, row in merged.iterrows():\n",
        "    val1 = row.get(\"Value_file1\")\n",
        "    val2 = row.get(\"Value_file2\")\n",
        "\n",
        "    if pd.isna(val1):\n",
        "        print(f\"❌ Missing in Glencore: {row['Week Range']} {row['Month']} → Value in Source = {val2}\")\n",
        "\n",
        "    elif pd.isna(val2):\n",
        "        print(f\"❌ Missing in Source: {row['Week Range']} {row['Month']} → Value in Glencore = {val1}\")\n",
        "\n",
        "    elif val1 != val2:\n",
        "        print(f\"❌ Mismatch on {row['Week Range']} {row['Month']} → Glencore: {val1}, Source: {val2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc9N1Re0UBpj",
        "outputId": "ca240d89-b839-49b8-8bbd-6e19bc418aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Mismatch on 1-5/9 Nov → Glencore: 70.0, Source: 82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "df1 = pd.read_csv(\"/content/data_cleaned_dfls_glencore.csv\")\n",
        "df2 = pd.read_csv(\"/content/data_cleaned_dfls_source.csv\")\n",
        "\n",
        "def normalize_month(month):\n",
        "    if pd.isna(month):\n",
        "        return month\n",
        "    month = month.strip().lower()\n",
        "\n",
        "    match = re.match(r'^20(\\d{2})$', month)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "\n",
        "    month = month.replace('cal', '')\n",
        "    month = month.replace('-', '')\n",
        "    return month\n",
        "\n",
        "df1['Month_norm'] = df1['Month'].apply(normalize_month)\n",
        "df2['Month_norm'] = df2['Month'].apply(normalize_month)\n",
        "\n",
        "merged = pd.merge(df1, df2, on='Month_norm', how='outer', suffixes=('_file1', '_file2'))\n",
        "\n",
        "for _, row in merged.iterrows():\n",
        "    m1 = row.get(\"Month_file1\")\n",
        "    m2 = row.get(\"Month_file2\")\n",
        "    v1 = row.get(\"Value_file1\")\n",
        "    v2 = row.get(\"Value_file2\")\n",
        "    label = row[\"Month_norm\"]\n",
        "\n",
        "    if pd.isna(v1):\n",
        "        print(f\"❌ Missing in Glencore: {m2} → Value in Source = {v2}\")\n",
        "    elif pd.isna(v2):\n",
        "        print(f\"❌ Missing in Source: {m1} → Value in Glencore = {v1}\")\n",
        "    elif float(v1) != float(v2):\n",
        "        print(f\"❌ Mismatch on '{label}' → Glencore: {v1}, Source: {v2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWRe-aSqZz4H",
        "outputId": "18f556cd-7011-43b9-c535-e603344e80b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Missing in Source: Dec → Value in Glencore = 7.0\n",
            "❌ Missing in Source: Feb → Value in Glencore = 6.0\n",
            "❌ Missing in Source: Jan → Value in Glencore = 7.0\n",
            "❌ Missing in Source: Nov → Value in Glencore = 19.0\n",
            "❌ Missing in Source: Oct → Value in Glencore = 39.0\n",
            "❌ Missing in Source: Sep → Value in Glencore = 61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv(\"/content/data_cleaned_efps_glencore.csv\")\n",
        "df2 = pd.read_csv(\"/content/data_cleaned_brent_efps_source.csv\")\n",
        "\n",
        "merged = pd.merge(df1, df2, on='Month', how='outer', suffixes=('_data1', '_data2'))\n",
        "\n",
        "merged['Value_data1'] = pd.to_numeric(merged['Value_data1'], errors='coerce')\n",
        "merged['Value_data2'] = pd.to_numeric(merged['Value_data2'], errors='coerce')\n",
        "\n",
        "for _, row in merged.iterrows():\n",
        "    month = row['Month']\n",
        "    v1 = row['Value_data1']\n",
        "    v2 = row['Value_data2']\n",
        "\n",
        "    if pd.isna(v1):\n",
        "        print(f\"Missing value in glencore for {month}, source value is {v2}\")\n",
        "    elif pd.isna(v2):\n",
        "        print(f\"Missing value in source for {month}, glencore value is {v1}\")\n",
        "    elif v1 != v2:\n",
        "        print(f\"Value in glencore is {v1}, value in source is {v2} — mismatch\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm1xSVbNZ_B6",
        "outputId": "e94252b6-bfd3-49ab-8468-61e74c6364fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing value in glencore for Nov, source value is 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv(\"data_cleaned_spreads_glencore.csv\")\n",
        "df2 = pd.read_csv(\"data_cleaned_spreads_source.csv\")\n",
        "\n",
        "df2['Spread'] = df2['Month1'] + \"/\" + df2['Month2'] + \" ICE\"\n",
        "\n",
        "merged = pd.merge(df2, df1, on='Spread', how='outer', suffixes=('_data2', '_data1'))\n",
        "\n",
        "merged['Value_data1'] = pd.to_numeric(merged['Value_data1'], errors='coerce')\n",
        "merged['Value_data2'] = pd.to_numeric(merged['Value_data2'], errors='coerce')\n",
        "\n",
        "for _, row in merged.iterrows():\n",
        "    spread = row['Spread']\n",
        "    v1 = row['Value_data1']\n",
        "    v2 = row['Value_data2']\n",
        "\n",
        "    if pd.isna(v1):\n",
        "        print(f\"Missing value in glencore for {spread}, source value is {v2}\")\n",
        "    elif pd.isna(v2):\n",
        "        print(f\"Missing value in source for {spread}, glencore value is {v1}\")\n",
        "    elif v1 != v2:\n",
        "        print(f\"Value in glencore is {v1}, value in source is {v2} — mismatch for {spread}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rZlxrn-cAeY",
        "outputId": "b167be6e-c47d-4a5a-8ee0-ae2b3e5a05c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing value in glencore for Dec/Jan ICE, source value is 14.0\n",
            "Missing value in source for Dec/Mar26, glencore value is 22.0\n",
            "Missing value in source for Dec25/Dec26, glencore value is 17.0\n",
            "Missing value in source for Dec26/Dec27, glencore value is -33.0\n",
            "Missing value in glencore for Jan/Feb ICE, source value is 5.0\n",
            "Missing value in source for Sep/Dec25, glencore value is 151.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_excel_sheet(file_path: str, sheet_name: str = \"Sheet1\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Loads the specified Excel sheet into a pandas DataFrame without headers.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the Excel file.\n",
        "        sheet_name (str): Name of the sheet to parse.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Raw data from the specified sheet.\n",
        "    \"\"\"\n",
        "    xls = pd.ExcelFile(file_path)\n",
        "    return xls.parse(sheet_name, header=None)\n",
        "\n",
        "def extract_weekly_cfds(sheet_data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extracts weekly CFD data starting from 'Week1' until the first non-'Week' row.\n",
        "\n",
        "    It captures columns: Week name, Date Range, Month, and Value.\n",
        "\n",
        "    Args:\n",
        "        sheet_data (pd.DataFrame): Raw Excel sheet data.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Cleaned DataFrame containing weekly CFD data.\n",
        "    \"\"\"\n",
        "    weekly_cfds_rows = []\n",
        "    collecting = False\n",
        "\n",
        "    for index, row in sheet_data.iterrows():\n",
        "        first_cell = str(row[0]).strip()\n",
        "\n",
        "        if first_cell.startswith(\"Week1\"):\n",
        "            collecting = True\n",
        "\n",
        "        if collecting:\n",
        "            if str(first_cell).startswith(\"Week\"):\n",
        "                weekly_cfds_rows.append([row[0], row[1], row[3], row[4]])\n",
        "            else:\n",
        "                break\n",
        "\n",
        "    return pd.DataFrame(weekly_cfds_rows, columns=['Week', 'Date Range', 'Month', 'Value']).reset_index(drop=True)\n",
        "\n",
        "def extract_dfls(sheet_data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extracts DFL data by collecting non-null values from columns 7 and 8.\n",
        "\n",
        "    Args:\n",
        "        sheet_data (pd.DataFrame): Raw Excel sheet data.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing DFL data with 'Month' and 'Value' columns.\n",
        "    \"\"\"\n",
        "    dfls_rows = []\n",
        "\n",
        "    for index, row in sheet_data.iterrows():\n",
        "        month = row[7]\n",
        "        value = row[8]\n",
        "\n",
        "        if pd.notna(month) and pd.notna(value):\n",
        "            dfls_rows.append([month, value])\n",
        "\n",
        "    return pd.DataFrame(dfls_rows, columns=['Month', 'Value'])\n",
        "\n",
        "def extract_spreads(sheet_data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extracts spread data by looking for rows where column 3 contains \"ICE\" or \"/\"\n",
        "    and column 4 has a value.\n",
        "\n",
        "    Args:\n",
        "        sheet_data (pd.DataFrame): Raw Excel sheet data.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing spread labels and their values.\n",
        "    \"\"\"\n",
        "    spreads_rows = []\n",
        "\n",
        "    for index, row in sheet_data.iterrows():\n",
        "        col3 = row[3]\n",
        "        col4 = row[4]\n",
        "\n",
        "        if pd.notna(col3) and pd.notna(col4):\n",
        "            if \"ICE\" in str(col3) or \"/\" in str(col3):\n",
        "                spreads_rows.append([col3, col4])\n",
        "\n",
        "    return pd.DataFrame(spreads_rows, columns=['Spread', 'Value'])\n",
        "\n",
        "def separate_efps(dfls_df: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Separates the last three rows from DFLs as EFPs and returns both DataFrames.\n",
        "\n",
        "    Args:\n",
        "        dfls_df (pd.DataFrame): Complete DFL DataFrame.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, pd.DataFrame]: DFL data excluding EFPs, and EFP data.\n",
        "    \"\"\"\n",
        "    efps_df = dfls_df.tail(3).reset_index(drop=True)\n",
        "    dfls_df = dfls_df.iloc[:-3].reset_index(drop=True)\n",
        "    return dfls_df, efps_df\n",
        "\n",
        "def save_to_csv(df: pd.DataFrame, output_path: str):\n",
        "    \"\"\"\n",
        "    Saves the given DataFrame to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Data to save.\n",
        "        output_path (str): Path for the output CSV file.\n",
        "    \"\"\"\n",
        "    df.to_csv(output_path, index=False)\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function that processes the Excel file:\n",
        "    - Extracts weekly CFDs, DFLs, Spreads, and EFPs\n",
        "    - Saves each dataset to separate CSV files\n",
        "    - Prints output confirmation\n",
        "    \"\"\"\n",
        "    file_path = \"/content/Glencore recap 11062025.xlsx\"\n",
        "\n",
        "    sheet_data = load_excel_sheet(file_path)\n",
        "\n",
        "    weekly_cfds_df = extract_weekly_cfds(sheet_data)\n",
        "    dfls_df = extract_dfls(sheet_data)\n",
        "    spreads_df = extract_spreads(sheet_data)\n",
        "    dfls_df, efps_df = separate_efps(dfls_df)\n",
        "\n",
        "    cfds_output_path = \"data_cleaned_cfds_glencore.csv\"\n",
        "    dfls_output_path = \"data_cleaned_dfls_glencore.csv\"\n",
        "    spreads_output_path = \"data_cleaned_spreads_glencore.csv\"\n",
        "    efp_output_path = \"data_cleaned_efps_glencore.csv\"\n",
        "\n",
        "    save_to_csv(weekly_cfds_df, cfds_output_path)\n",
        "    save_to_csv(dfls_df, dfls_output_path)\n",
        "    save_to_csv(spreads_df, spreads_output_path)\n",
        "    save_to_csv(efps_df, efp_output_path)\n",
        "\n",
        "    print(\"✅ Files saved:\")\n",
        "    print(f\" - CFDs: {cfds_output_path}\")\n",
        "    print(f\" - DFLs: {dfls_output_path}\")\n",
        "    print(f\" - Spreads: {spreads_output_path}\")\n",
        "    print(f\" - EFPs: {efp_output_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "cjW4kiHrS7OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_excel_sheet(file_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Loads the first sheet of an Excel file as a pandas DataFrame with no headers.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the Excel file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing all sheet data.\n",
        "    \"\"\"\n",
        "    xls = pd.ExcelFile(file_path)\n",
        "    return xls.parse(xls.sheet_names[0], header=None)\n",
        "\n",
        "def extract_weekly_cfds(sheet_data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extracts CFD data starting after the row containing \"CFD's\".\n",
        "    Stops when it encounters an empty row or a row containing \"All Month\".\n",
        "\n",
        "    Args:\n",
        "        sheet_data (pd.DataFrame): The entire Excel sheet as a DataFrame.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing columns ['Week Range', 'Month', 'Value'].\n",
        "    \"\"\"\n",
        "    weekly_cfds_rows = []\n",
        "    cfds_section_found = False\n",
        "\n",
        "    for _, row in sheet_data.iterrows():\n",
        "        row_str = str(row[0])\n",
        "\n",
        "        if \"CFD's\" in row_str:\n",
        "            cfds_section_found = True\n",
        "            continue\n",
        "\n",
        "        if cfds_section_found:\n",
        "            if pd.notna(row[0]) and pd.notna(row[1]) and pd.notna(row[2]):\n",
        "                weekly_cfds_rows.append([row[0], row[1], row[2]])\n",
        "            elif pd.isna(row[0]) or \"All Month\" in str(row[0]):\n",
        "                break\n",
        "\n",
        "    return pd.DataFrame(weekly_cfds_rows, columns=['Week Range', 'Month', 'Value'])\n",
        "\n",
        "def extract_dfls(sheet_data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extracts DFL data from the sheet after finding the row \"Dated Front Line ICE\".\n",
        "    Stops before the row containing \"Calendar WTI/Brent Swap\".\n",
        "\n",
        "    Args:\n",
        "        sheet_data (pd.DataFrame): The entire Excel sheet as a DataFrame.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing DFL data with ['Month', 'Value'].\n",
        "    \"\"\"\n",
        "    dfls_rows = []\n",
        "    dfl_section_found = False\n",
        "\n",
        "    for _, row in sheet_data.iterrows():\n",
        "        col_f = str(row[5]).strip() if pd.notna(row[5]) else \"\"\n",
        "        col_g = row[6]\n",
        "\n",
        "        if not dfl_section_found:\n",
        "            if col_f == \"Dated Front Line ICE\":\n",
        "                dfl_section_found = True\n",
        "            continue\n",
        "\n",
        "        if dfl_section_found:\n",
        "            if \"Calendar WTI/Brent Swap\" in col_f:\n",
        "                break\n",
        "            if col_f and pd.notna(col_g):\n",
        "                dfls_rows.append([col_f, col_g])\n",
        "\n",
        "    return pd.DataFrame(dfls_rows, columns=['Month', 'Value'])\n",
        "\n",
        "def extract_spreads(sheet_data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extracts Brent spread data after identifying the row containing \"Brent Spreads\".\n",
        "    Collects rows with three non-null values and stops at a fully empty row.\n",
        "\n",
        "    Args:\n",
        "        sheet_data (pd.DataFrame): The entire Excel sheet as a DataFrame.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing ['Month1', 'Month2', 'Value'].\n",
        "    \"\"\"\n",
        "    spreads_rows = []\n",
        "    spreads_started = False\n",
        "\n",
        "    for _, row in sheet_data.iterrows():\n",
        "        col_k = str(row[10]).strip() if pd.notna(row[10]) else \"\"\n",
        "        col_l = str(row[11]).strip() if pd.notna(row[11]) else \"\"\n",
        "        col_m = row[12]\n",
        "\n",
        "        if not spreads_started and \"Brent Spreads\" in col_l:\n",
        "            spreads_started = True\n",
        "            continue\n",
        "\n",
        "        if spreads_started:\n",
        "            if not col_k and not col_l and pd.isna(col_m):\n",
        "                break\n",
        "            if col_k and col_l and pd.notna(col_m):\n",
        "                spreads_rows.append([col_k, col_l, col_m])\n",
        "\n",
        "    return pd.DataFrame(spreads_rows, columns=[\"Month1\", \"Month2\", \"Value\"])\n",
        "\n",
        "def extract_brent_efps(sheet_data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extracts Brent EFP data starting after the row containing \"Brent EFP\".\n",
        "    Stops at the first fully empty row and collects pairs of [Month, Value].\n",
        "\n",
        "    Args:\n",
        "        sheet_data (pd.DataFrame): The entire Excel sheet as a DataFrame.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing Brent EFPs with ['Month', 'Value'].\n",
        "    \"\"\"\n",
        "    brent_efps_rows = []\n",
        "    efp_section_started = False\n",
        "\n",
        "    for _, row in sheet_data.iterrows():\n",
        "        col_a = str(row[0]).strip() if pd.notna(row[0]) else \"\"\n",
        "        col_b = row[1]\n",
        "\n",
        "        if not efp_section_started and \"Brent EFP\" in col_a:\n",
        "            efp_section_started = True\n",
        "            continue\n",
        "\n",
        "        if efp_section_started:\n",
        "            if not col_a and pd.isna(col_b):\n",
        "                break\n",
        "            if col_a and pd.notna(col_b):\n",
        "                brent_efps_rows.append([col_a, col_b])\n",
        "\n",
        "    return pd.DataFrame(brent_efps_rows, columns=[\"Month\", \"Value\"])\n",
        "\n",
        "def save_to_csv(df: pd.DataFrame, output_path: str):\n",
        "    \"\"\"\n",
        "    Saves a DataFrame to a CSV file without the index column.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The data to save.\n",
        "        output_path (str): Output path of the CSV file.\n",
        "    \"\"\"\n",
        "    df.to_csv(output_path, index=False)\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to extract CFDs, DFLs, Spreads, and Brent EFPs from an Excel file,\n",
        "    and save each section into separate CSV files. Also prints the output paths.\n",
        "    \"\"\"\n",
        "    file_path = \"marketclose 11062025.xls\"\n",
        "    sheet_data = load_excel_sheet(file_path)\n",
        "\n",
        "    weekly_cfds_df = extract_weekly_cfds(sheet_data)\n",
        "    dfls_df = extract_dfls(sheet_data)\n",
        "    spreads_df = extract_spreads(sheet_data)\n",
        "    brent_efps_df = extract_brent_efps(sheet_data)\n",
        "\n",
        "    save_to_csv(weekly_cfds_df, \"data_cleaned_cfds_source.csv\")\n",
        "    save_to_csv(dfls_df, \"data_cleaned_dfls_source.csv\")\n",
        "    save_to_csv(spreads_df, \"data_cleaned_spreads_source.csv\")\n",
        "    save_to_csv(brent_efps_df, \"data_cleaned_brent_efps_source.csv\")\n",
        "\n",
        "    print(\"✅ Files saved:\")\n",
        "    print(\" - CFDs: data_cleaned_cfds_source.csv\")\n",
        "    print(\" - DFLs: data_cleaned_dfls_source.csv\")\n",
        "    print(\" - Spreads: data_cleaned_spreads_source.csv\")\n",
        "    print(\" - Brent EFPs: data_cleaned_brent_efps_source.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "vtdYPr1DTIHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_and_prepare_csv(path: str, rename_cols: dict = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Loads a CSV and optionally renames columns, then strips whitespace from 'Week Range' and 'Month'.\n",
        "\n",
        "    Args:\n",
        "        path (str): Path to the CSV file.\n",
        "        rename_cols (dict, optional): Dictionary for renaming columns.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Cleaned DataFrame with normalized keys.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    if rename_cols:\n",
        "        df.rename(columns=rename_cols, inplace=True)\n",
        "\n",
        "    df[\"Week Range\"] = df[\"Week Range\"].astype(str).str.strip()\n",
        "    df[\"Month\"] = df[\"Month\"].astype(str).str.strip()\n",
        "\n",
        "    return df\n",
        "\n",
        "def compare_cfd_values(df1: pd.DataFrame, df2: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Compares the 'Value' fields between two CFD DataFrames based on 'Week Range' and 'Month'.\n",
        "    Prints differences, including mismatches and missing values from either file.\n",
        "\n",
        "    Args:\n",
        "        df1 (pd.DataFrame): First CFD DataFrame (e.g., Glencore).\n",
        "        df2 (pd.DataFrame): Second CFD DataFrame (e.g., Source).\n",
        "    \"\"\"\n",
        "    merged = pd.merge(df1, df2, on=[\"Week Range\", \"Month\"], how=\"outer\", suffixes=('_file1', '_file2'))\n",
        "\n",
        "    for _, row in merged.iterrows():\n",
        "        val1 = row.get(\"Value_file1\")\n",
        "        val2 = row.get(\"Value_file2\")\n",
        "\n",
        "        if pd.isna(val1):\n",
        "            print(f\"❌ Missing in Glencore: {row['Week Range']} {row['Month']} → Value in Source = {val2}\")\n",
        "\n",
        "        elif pd.isna(val2):\n",
        "            print(f\"❌ Missing in Source: {row['Week Range']} {row['Month']} → Value in Glencore = {val1}\")\n",
        "\n",
        "        elif val1 != val2:\n",
        "            print(f\"❌ Mismatch on {row['Week Range']} {row['Month']} → Glencore: {val1}, Source: {val2}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to compare CFD values between Glencore and Source datasets.\n",
        "    Identifies mismatched or missing values between the two.\n",
        "    \"\"\"\n",
        "    path_glencore = \"/content/data_cleaned_cfds_glencore.csv\"\n",
        "    path_source = \"/content/data_cleaned_cfds_source.csv\"\n",
        "\n",
        "    df_glencore = load_and_prepare_csv(path_glencore, rename_cols={\"Date Range\": \"Week Range\"})\n",
        "    df_source = load_and_prepare_csv(path_source)\n",
        "\n",
        "    compare_cfd_values(df_glencore, df_source)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "bbAHG1QWVeh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def normalize_month(month: str) -> str:\n",
        "    \"\"\"\n",
        "    Normalizes month strings to a comparable format by:\n",
        "    - Converting to lowercase\n",
        "    - Removing 'cal' and hyphens\n",
        "    - Stripping whitespace\n",
        "    - Converting '2026' → '26', etc.\n",
        "\n",
        "    Args:\n",
        "        month (str): Original month string.\n",
        "\n",
        "    Returns:\n",
        "        str: Normalized month string, or original if NaN.\n",
        "    \"\"\"\n",
        "    if pd.isna(month):\n",
        "        return month\n",
        "    month = month.strip().lower()\n",
        "\n",
        "    match = re.match(r'^20(\\d{2})$', month)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "\n",
        "    month = month.replace('cal', '')\n",
        "    month = month.replace('-', '')\n",
        "    return month\n",
        "\n",
        "def load_and_prepare_dfl(path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Loads a DFL CSV and applies month normalization.\n",
        "\n",
        "    Args:\n",
        "        path (str): Path to the DFL CSV file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with normalized month column 'Month_norm'.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    df['Month_norm'] = df['Month'].apply(normalize_month)\n",
        "    return df\n",
        "\n",
        "def compare_dfl_values(df1: pd.DataFrame, df2: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Merges two DFL DataFrames on normalized months and prints mismatches,\n",
        "    missing entries, and inconsistent values.\n",
        "\n",
        "    Args:\n",
        "        df1 (pd.DataFrame): Glencore DFL data.\n",
        "        df2 (pd.DataFrame): Source DFL data.\n",
        "    \"\"\"\n",
        "    merged = pd.merge(df1, df2, on='Month_norm', how='outer', suffixes=('_file1', '_file2'))\n",
        "\n",
        "    for _, row in merged.iterrows():\n",
        "        m1 = row.get(\"Month_file1\")\n",
        "        m2 = row.get(\"Month_file2\")\n",
        "        v1 = row.get(\"Value_file1\")\n",
        "        v2 = row.get(\"Value_file2\")\n",
        "        label = row[\"Month_norm\"]\n",
        "\n",
        "        if pd.isna(v1):\n",
        "            print(f\"❌ Missing in Glencore: {m2} → Value in Source = {v2}\")\n",
        "        elif pd.isna(v2):\n",
        "            print(f\"❌ Missing in Source: {m1} → Value in Glencore = {v1}\")\n",
        "        elif float(v1) != float(v2):\n",
        "            print(f\"❌ Mismatch on '{label}' → Glencore: {v1}, Source: {v2}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to:\n",
        "    - Load Glencore and Source DFL data\n",
        "    - Normalize months\n",
        "    - Compare and report mismatches or missing values\n",
        "    \"\"\"\n",
        "    df1 = load_and_prepare_dfl(\"/content/data_cleaned_dfls_glencore.csv\")\n",
        "    df2 = load_and_prepare_dfl(\"/content/data_cleaned_dfls_source.csv\")\n",
        "    compare_dfl_values(df1, df2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "4G1G4kfuWkxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_and_clean_efp(path: str, value_col: str = \"Value\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Loads an EFP CSV and ensures the value column is numeric.\n",
        "\n",
        "    Args:\n",
        "        path (str): Path to the EFP CSV file.\n",
        "        value_col (str): Column name that holds the numeric value.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Cleaned EFP DataFrame with numeric values.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    df[value_col] = pd.to_numeric(df[value_col], errors='coerce')\n",
        "    return df\n",
        "\n",
        "def compare_efp_values(df1: pd.DataFrame, df2: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Compares EFP values from two sources by merging on the 'Month' column.\n",
        "    Prints out mismatches and missing values.\n",
        "\n",
        "    Args:\n",
        "        df1 (pd.DataFrame): Glencore EFP data.\n",
        "        df2 (pd.DataFrame): Source Brent EFP data.\n",
        "    \"\"\"\n",
        "    merged = pd.merge(df1, df2, on='Month', how='outer', suffixes=('_data1', '_data2'))\n",
        "\n",
        "    for _, row in merged.iterrows():\n",
        "        month = row['Month']\n",
        "        v1 = row['Value_data1']\n",
        "        v2 = row['Value_data2']\n",
        "\n",
        "        if pd.isna(v1):\n",
        "            print(f\"❌ Missing value in Glencore for {month}, Source value = {v2}\")\n",
        "        elif pd.isna(v2):\n",
        "            print(f\"❌ Missing value in Source for {month}, Glencore value = {v1}\")\n",
        "        elif v1 != v2:\n",
        "            print(f\"❌ Mismatch in {month} → Glencore: {v1}, Source: {v2}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Loads and compares EFP values from Glencore and Source files,\n",
        "    identifying any mismatches or missing data.\n",
        "    \"\"\"\n",
        "    df1 = load_and_clean_efp(\"/content/data_cleaned_efps_glencore.csv\")\n",
        "    df2 = load_and_clean_efp(\"/content/data_cleaned_brent_efps_source.csv\")\n",
        "    compare_efp_values(df1, df2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "mS5VLufyXAMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_and_prepare_spreads(glencore_path: str, source_path: str) -> (pd.DataFrame, pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Loads and prepares spread data from Glencore and Source files.\n",
        "    For the source file, constructs a unified 'Spread' column from Month1 and Month2.\n",
        "\n",
        "    Args:\n",
        "        glencore_path (str): Path to Glencore spreads CSV.\n",
        "        source_path (str): Path to Source spreads CSV.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, pd.DataFrame]: Prepared Glencore and Source DataFrames.\n",
        "    \"\"\"\n",
        "    df1 = pd.read_csv(glencore_path)\n",
        "    df2 = pd.read_csv(source_path)\n",
        "\n",
        "    df2['Spread'] = df2['Month1'].astype(str).str.strip() + \"/\" + df2['Month2'].astype(str).str.strip() + \" ICE\"\n",
        "\n",
        "    df1['Value'] = pd.to_numeric(df1['Value'], errors='coerce')\n",
        "    df2['Value'] = pd.to_numeric(df2['Value'], errors='coerce')\n",
        "\n",
        "    return df1, df2\n",
        "\n",
        "def compare_spread_values(df_glencore: pd.DataFrame, df_source: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Merges and compares spread values from Glencore and Source on the 'Spread' column.\n",
        "    Prints mismatches and missing values from either side.\n",
        "\n",
        "    Args:\n",
        "        df_glencore (pd.DataFrame): Glencore spread data.\n",
        "        df_source (pd.DataFrame): Source spread data with constructed 'Spread' column.\n",
        "    \"\"\"\n",
        "    merged = pd.merge(df_source, df_glencore, on='Spread', how='outer', suffixes=('_data2', '_data1'))\n",
        "\n",
        "    for _, row in merged.iterrows():\n",
        "        spread = row['Spread']\n",
        "        v1 = row['Value_data1']\n",
        "        v2 = row['Value_data2']\n",
        "\n",
        "        if pd.isna(v1):\n",
        "            print(f\"❌ Missing in Glencore for {spread}, Source value = {v2}\")\n",
        "        elif pd.isna(v2):\n",
        "            print(f\"❌ Missing in Source for {spread}, Glencore value = {v1}\")\n",
        "        elif v1 != v2:\n",
        "            print(f\"❌ Mismatch in {spread} → Glencore: {v1}, Source: {v2}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function for comparing Brent Spread values between\n",
        "    Glencore and Source datasets. Outputs mismatches and missing data.\n",
        "    \"\"\"\n",
        "    glencore_path = \"data_cleaned_spreads_glencore.csv\"\n",
        "    source_path = \"data_cleaned_spreads_source.csv\"\n",
        "\n",
        "    df_glencore, df_source = load_and_prepare_spreads(glencore_path, source_path)\n",
        "    compare_spread_values(df_glencore, df_source)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "LNusp9G2XM9F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}